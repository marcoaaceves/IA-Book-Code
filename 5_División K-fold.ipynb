{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demanding-lloyd",
   "metadata": {},
   "source": [
    "# División *k-fold*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-inflation",
   "metadata": {},
   "source": [
    "Dividir un conjunto de datos conjuntos de entrenamiento y prueba, es una buena técnica para cuando queremos evaluar un algoritmo de *machine learning*, pero, dividir los datos en solo dos conjuntos puede arrojar resultados muy sesgados.\n",
    "\n",
    "*K-fold* es una alternativa para evitar este problema, ya que, nos permite dividir los datos en *k* particiones homogéneas, dónde, se utilizará cada una de estas particiones como conjunto de prueba mientras las demás se utilizan como entrenamiento, en un proceso iterativo de *k* iteraciones.\n",
    "\n",
    "En la siguiente imagen se ilustra como se dividen los datos, cuando *k = 5*. El color verde se refiere al conjunto de entrenamiento y el color amarillo al conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-rugby",
   "metadata": {},
   "source": [
    "![k-fold](kfold.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-confidence",
   "metadata": {},
   "source": [
    "Hagamos el código para realizar las divisiones.\n",
    "\n",
    "Importamos librerías de utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infinite-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-replica",
   "metadata": {},
   "source": [
    "Abrimos la base de datos que vamos a utilizar, **EnfCoronaria**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>famhist</th>\n",
       "      <th>obesity</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>25.30</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>28.87</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>29.14</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>31.99</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>25.99</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  famhist  obesity  age  chd\n",
       "0  160        1    25.30   52    1\n",
       "1  144        0    28.87   63    1\n",
       "2  118        1    29.14   46    0\n",
       "3  170        1    31.99   58    1\n",
       "4  134        1    25.99   49    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"EnfCoronaria.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-participation",
   "metadata": {},
   "source": [
    "Las particiones las realizaremos a través de una función que llamaremos **particion**, en la cual, haremos las particiones de la manera más homogéna que podamos, esta función recibirá como parámetros la base de datos **df** y el número de particiones a realizar **k**. Creamos una lista donde guardaremos las divisiones, llamada **datos**, obtenemos el número de elementos en la base de datos y lo guardamos en **tamano**, este valor tiene que ser entero, por lo tanto, al momento de guardar el valor, lo convertimos a entero (a esto se le conoce como *casting*), porque la división entre el número de datos y las particiones a crear, usualmente, será un número tipo *float*. El siguiente paso es hacer un ciclo *for* donde iremos asignando los índices de cada partición, el rango de cada partición lo determinamos utilizando la función ***range***, donde le mandaremos los parámetros, **i\\*tamano** (límite inferior) y **(i+1)\\*tamano** (límite superior), este rango lo vamos a guardar como un arreglo, y lo agregamos a la lista **datos**, este ciclo lo ejecutaremos *k-1* veces, ya que para la última partición, los límites serán **(i+1)\\*tamano** (límite inferior) y ***len(df)*** (límite superior), de modo que, si se realizó un *casting* cuando obtuvimos **tamano**, no se pierdan elementos, por ejemplo, si tenemos 27 datos en total y queremos 5 particiones, el tamaño de la partición sería de 27/5 = 5.4, al realizar el *casting* el tamaño nos quedaría de 5, pero, si hacemos todas las particiones de 5 elementos al final tendríamos 25 datos en lugar de 27, para evitar esto, lo que hacemos es que las primeras 4 particiones las hacemos de 5 elementos y, la última partición, la hacemos de los elementos restantes, 7 en este caso, y así al final tenemos los 27 datos, aunque nuestra última partición es ligeramente más grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(df, k):\n",
    "    # lista donde guardaremos las particiones\n",
    "    datos = []\n",
    "    # obtenemos el total de datos en la BD\n",
    "    tamano = int(len(df)/k)\n",
    "    # comenzamos a realizar las particiones\n",
    "    for i in range(k-1):\n",
    "        # indices de cada partición\n",
    "        division = np.array(range(i*tamano, (i+1)*tamano))\n",
    "        # guardamos la partición en datos\n",
    "        datos.append(np.array(division))\n",
    "    # última división\n",
    "    datos.append(np.array(range((i+1)*tamano, len(df))))\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-skating",
   "metadata": {},
   "source": [
    "Ya con las particiones creadas, haremos otra función llamada **conjunto**, que nos servirá para obtener los conjuntos de entrenamiento y prueba. Esta función recibe tres parámetros, la base de datos **df**, la lista de particiones **datos**, y el índice **indice** que indica el número de iteración y, por ende, la posición del conjunto de prueba. Para crear un conjunto de datos a partir de un *data frame*, usamos la función ***iloc*** de ***pandas*** que filtra los datos de acuerdo con los índices que recibe como parámetro. El conjunto de prueba, lo podemos crear mandando **datos[indice]**, como parámetro a ***iloc***; el conjunto de entrenamiento, consiste en todos los datos, excepto los que usamos como prueba, entonces para obtener estos datos podemos obtener los índices de todos los datos en **df**, usando ***np.array(range(len(df))***, y eliminando los índices del conjunto de datos con la función ***delete*** de ***numpy***, está función, recibe como parámetros el *array* sobre el que se va a trabajar y las posiciones que se van a eliminar, entonces, usando ***np.delete(ind, datos[indice])***, le estamos diciendo que trabaje sobre los índices de todo el archivo y después elimine los que usamos como prueba. Hecho esto, usamos de nuevo ***iloc*** para obtener los datos correspondientes al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electoral-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjunto(df, datos, indice):\n",
    "    # creamos el conjunto de prueba\n",
    "    prueba = df.iloc[datos[indice]]\n",
    "    # sacamos los indices de toda la BD\n",
    "    ind = np.array(range(len(df)))\n",
    "    # eliminamos los indices del conjunto de prueba\n",
    "    ind_ent = np.delete(ind, datos[indice])\n",
    "    # creamos el conjunto de entrenamiento\n",
    "    entrenamiento = df.iloc[ind_ent]\n",
    "    return entrenamiento, prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-principal",
   "metadata": {},
   "source": [
    "Probemos nuestro algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "irish-helicopter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]),\n",
       " array([115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
       "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
       "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229]),\n",
       " array([230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
       "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
       "        256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
       "        269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
       "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
       "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
       "        321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
       "        334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344]),\n",
       " array([345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357,\n",
       "        358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
       "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
       "        384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
       "        397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
       "        410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
       "        423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
       "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
       "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numero de particiones que queremos\n",
    "k = 4\n",
    "# mandamos llamar a division() para crear las particiones\n",
    "datos = particion(df, k)\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electrical-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 1\n",
      "Entrenamiento:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "115  128        1    28.41   48    0\n",
      "116  140        0    21.91   32    1\n",
      "117  154        0    20.60   42    0\n",
      "118  150        1    23.35   61    1\n",
      "119  130        0    28.02   27    0\n",
      "..   ...      ...      ...  ...  ...\n",
      "457  214        0    28.45   58    0\n",
      "458  182        0    28.61   52    1\n",
      "459  108        0    20.09   55    0\n",
      "460  118        0    27.35   40    0\n",
      "461  132        1    14.70   46    1\n",
      "\n",
      "[347 rows x 5 columns]\n",
      "Prueba:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "0    160        1    25.30   52    1\n",
      "1    144        0    28.87   63    1\n",
      "2    118        1    29.14   46    0\n",
      "3    170        1    31.99   58    1\n",
      "4    134        1    25.99   49    1\n",
      "..   ...      ...      ...  ...  ...\n",
      "110  114        0    25.51   16    0\n",
      "111  168        1    26.18   54    1\n",
      "112  134        0    21.03   37    0\n",
      "113  174        1    25.27   61    1\n",
      "114  116        0    19.40   59    1\n",
      "\n",
      "[115 rows x 5 columns]\n",
      "Iteración: 2\n",
      "Entrenamiento:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "0    160        1    25.30   52    1\n",
      "1    144        0    28.87   63    1\n",
      "2    118        1    29.14   46    0\n",
      "3    170        1    31.99   58    1\n",
      "4    134        1    25.99   49    1\n",
      "..   ...      ...      ...  ...  ...\n",
      "457  214        0    28.45   58    0\n",
      "458  182        0    28.61   52    1\n",
      "459  108        0    20.09   55    0\n",
      "460  118        0    27.35   40    0\n",
      "461  132        1    14.70   46    1\n",
      "\n",
      "[347 rows x 5 columns]\n",
      "Prueba:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "115  128        1    28.41   48    0\n",
      "116  140        0    21.91   32    1\n",
      "117  154        0    20.60   42    0\n",
      "118  150        1    23.35   61    1\n",
      "119  130        0    28.02   27    0\n",
      "..   ...      ...      ...  ...  ...\n",
      "225  143        0    24.69   42    0\n",
      "226  112        1    27.29   32    1\n",
      "227  134        0    28.33   52    1\n",
      "228  138        1    27.25   64    1\n",
      "229  188        1    28.99   50    1\n",
      "\n",
      "[115 rows x 5 columns]\n",
      "Iteración: 3\n",
      "Entrenamiento:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "0    160        1    25.30   52    1\n",
      "1    144        0    28.87   63    1\n",
      "2    118        1    29.14   46    0\n",
      "3    170        1    31.99   58    1\n",
      "4    134        1    25.99   49    1\n",
      "..   ...      ...      ...  ...  ...\n",
      "457  214        0    28.45   58    0\n",
      "458  182        0    28.61   52    1\n",
      "459  108        0    20.09   55    0\n",
      "460  118        0    27.35   40    0\n",
      "461  132        1    14.70   46    1\n",
      "\n",
      "[347 rows x 5 columns]\n",
      "Prueba:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "230  110        1    26.08   58    1\n",
      "231  136        0    29.19   62    0\n",
      "232  130        0    29.42   58    1\n",
      "233  122        0    24.36   30    0\n",
      "234  138        0    25.70   29    0\n",
      "..   ...      ...      ...  ...  ...\n",
      "340  118        0    25.89   40    0\n",
      "341  116        1    23.31   52    1\n",
      "342  162        1    20.43   53    1\n",
      "343  138        0    26.76   31    0\n",
      "344  137        0    24.13   37    0\n",
      "\n",
      "[115 rows x 5 columns]\n",
      "Iteración: 4\n",
      "Entrenamiento:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "0    160        1    25.30   52    1\n",
      "1    144        0    28.87   63    1\n",
      "2    118        1    29.14   46    0\n",
      "3    170        1    31.99   58    1\n",
      "4    134        1    25.99   49    1\n",
      "..   ...      ...      ...  ...  ...\n",
      "340  118        0    25.89   40    0\n",
      "341  116        1    23.31   52    1\n",
      "342  162        1    20.43   53    1\n",
      "343  138        0    26.76   31    0\n",
      "344  137        0    24.13   37    0\n",
      "\n",
      "[345 rows x 5 columns]\n",
      "Prueba:\n",
      "     sbp  famhist  obesity  age  chd\n",
      "345  198        1    28.40   26    1\n",
      "346  154        1    25.76   53    1\n",
      "347  128        0    18.36   61    0\n",
      "348  130        1    24.98   43    1\n",
      "349  162        0    22.91   60    0\n",
      "..   ...      ...      ...  ...  ...\n",
      "457  214        0    28.45   58    0\n",
      "458  182        0    28.61   52    1\n",
      "459  108        0    20.09   55    0\n",
      "460  118        0    27.35   40    0\n",
      "461  132        1    14.70   46    1\n",
      "\n",
      "[117 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# creamos dos listas donde guardaremos nuestros datos\n",
    "train = []\n",
    "test = []\n",
    "# obtenemos los conjuntos llamando a conjunto()\n",
    "for i in range(k):\n",
    "    entrenamiento, prueba = conjunto(df, datos, i)\n",
    "    print(\"Iteración:\", i + 1)\n",
    "    print(\"Entrenamiento:\")\n",
    "    print(entrenamiento)\n",
    "    print(\"Prueba:\")\n",
    "    print(prueba)\n",
    "    # agregamos los conjuntos a las listas\n",
    "    train.append(entrenamiento)\n",
    "    test.append(prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-hopkins",
   "metadata": {},
   "source": [
    "Y preguntamos si queremos exportar los datos a un archivo. Si la respuesta es afirmativa, guardaremos cada subconjunto de entrenamiento con su respectivo subconjunto de prueba, enumerándolos desde 0 hasta *k*-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imposed-performer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Desea guardar los datos en un archivo? s/n\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "guardar = input(\"¿Desea guardar los datos en un archivo? s/n\\n\")\n",
    "if guardar.lower() == \"s\":\n",
    "    for i in range(k):\n",
    "        n_train = \"train_\" + str(i) + \".csv\"\n",
    "        train[i].to_csv(n_train)\n",
    "        n_test = \"test_\" + str(i) + \".csv\"\n",
    "        test[i].to_csv(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-berkeley",
   "metadata": {},
   "source": [
    "Hecho esto, los archivos se crearán en el directorio en el que estemos trabajando.\n",
    "![archivos](archivos_kfold.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
