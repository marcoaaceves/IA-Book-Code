{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 0.1.1 - 2025 - 06 - 01\n",
        "#### Dr. Marco Antonio Aceves\n",
        "#### rev en Jupyter Notebook\n",
        "#### Código como ejemplo como parte del libro:\n",
        "#### de 0 a 100 en Inteligencia Artificial\n",
        "#### 4_Q-Learning"
      ],
      "metadata": {
        "id": "evCkW2GerQyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gym gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "hZ3yHIJc4q-D",
        "outputId": "006560d9-781b-4bbd-dcab-e5241231531c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Collecting gym\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827728 sha256=61161561f40e2e6a21f8ead0f17d4383b925d3467be6603fe175389c22e4a013\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              },
              "id": "52da335e4ddc4ed494cc11ff400d0301"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar librerías\n",
        "import numpy as np\n",
        "import gym"
      ],
      "metadata": {
        "id": "lk1nn7zPq6Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el entorno FrozenLake (4x4)\n",
        "\n",
        "# is_slippery=False para que no sea aleatorio\n",
        "env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
        "\n",
        "# Parámetros del entorno\n",
        "# 16 estados\n",
        "n_states = env.observation_space.n\n",
        "# 4 acciones (izq, abajo, der, arriba)\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "\n",
        "# Crear e inicializar la tabla Q\n",
        "Q = np.zeros((n_states, n_actions))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I6YrCswzrGwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de Q-learning\n",
        "# El significado de cada parámetro se muestra en el libro\n",
        "alpha = 0.1      # Tasa de aprendizaje\n",
        "gamma = 0.99     # Factor de descuento\n",
        "epsilon = 0.1    # Exploración\n",
        "n_episodes = 1000"
      ],
      "metadata": {
        "id": "9oiD_mkMuNZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "for episode in range(n_episodes):\n",
        "    # En las versiones recientes de gym/gymnasium, env.reset() devuelve una tupla (observation, info)\n",
        "    state, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Elegir acción (exploración vs explotación)\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()  # Explora\n",
        "        else:\n",
        "            action = np.argmax(Q[state])        # Explota\n",
        "        # En las versiones recientes de gym/gymnasium, step() devuelve una tupla (observation, reward, terminated, truncated, info)\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        # 'done' en la API antigua es 'terminated or truncated' en la nueva API\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # Actualización Q-learning\n",
        "        best_next_action = np.max(Q[next_state])\n",
        "        Q[state, action] += alpha * (reward + gamma * best_next_action - Q[state, action])\n",
        "\n",
        "        # Pasar al siguiente estado\n",
        "        state = next_state\n",
        "\n",
        "# Mostrar la tabla Q aprendida\n",
        "print(\"Tabla Q (valores aprendidos):\")\n",
        "print(np.round(Q, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFAJctpWwDmm",
        "outputId": "d05a800c-77a6-46a6-dd57-5d45fad26fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla Q (valores aprendidos):\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}